{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import sklearn.feature_extraction as ftex\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words, Bag of Popcorn\n",
    "\n",
    "[Bag of Words, Bag of Popcorn](https://www.kaggle.com/c/word2vec-nlp-tutorial/data) competition. \n",
    "\n",
    "NLP feature pre-processing (using SKLearn and NLTK) to build the best classifier possible with a feature pipeline, and gridsearch for your final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"data/labeledTrainData.tsv\", sep=\"\\t\")\n",
    "df[\"ogreview\"]=df.review\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replace={\n",
    "    \"<br /><br />\" :\"\",\n",
    "    \"...\": \".\",\n",
    "    \"..\": \".\",\n",
    "    '\"': \"\",\n",
    "    \"'s\": \"\"\n",
    "\n",
    "}\n",
    "def cleanup(series, dic):\n",
    "    for key in dic.keys():\n",
    "        series=series.str.replace(key, dic[key], regex=False)\n",
    "\n",
    "    return series\n",
    "# cleanup(df.review, to_replace)[0]\n",
    "\n",
    "df[\"line1\"]=df.review.str.split(\".\").str[0]\n",
    "df[\"end1\"]=df.review.str.split(\".\").str[-2]\n",
    "df[\"end2\"]=df.review.str.split(\".\").str[-3]\n",
    "\n",
    "df.review = df.review.str.lower()\n",
    "df.review=cleanup(df.review, to_replace)\n",
    "#do split line before this bit\n",
    "#clean un \\ and other random char\n",
    "df[[\"review\", \"line1\", \"end1\", \"end2\"]]=df[[\"review\",\"line1\", \"end1\", \"end2\"]].apply(lambda x: x.str.replace('[^a-zA-Z0-9 ]', '', regex=True), axis=1, ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df[\"text\"]=df.review +\" \"+ df.line1+\" \"+df.end1+\" \"+df.end2\n",
    "df[\"text\"]=df.review\n",
    "\n",
    "\n",
    "x, x_holdout,y, y_holdout = train_test_split(df.drop(columns=['sentiment']).text, df.sentiment, train_size=0.9, random_state=0)\n",
    "\n",
    "idf=ftex.text.TfidfVectorizer(stop_words=\"english\", min_df=5, max_df=0.9, strip_accents=\"ascii\")\n",
    "# vect=CountVectorizer(stop_words=\"english\", min_df=5, max_df=0.9, strip_accents=\"ascii\")\n",
    "\n",
    "e=[]\n",
    "s=[]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "{}\n",
      "0.8617333333333332\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "pipeline=Pipeline(\n",
    "    [   \n",
    "        (\"vect\", idf),\n",
    "        # ('darth', add_vader),\n",
    "\n",
    "\n",
    "        ('clf', MultinomialNB()),\n",
    "        # ('knn', KNeighborsClassifier()),\n",
    "        # ('dtree', DecisionTreeClassifier()), \n",
    "        # ('line_svc', SVC(kernel=\"linear\")), #too slow\n",
    "\n",
    "        # ('tsvd', TruncatedSVD()), #for svc models\n",
    "        # ('svc', SVC()),\n",
    "\n",
    "        # ('randomf', RandomForestClassifier())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# pipeline.fit(x, y)\n",
    "# pipeline.score(x_holdout, y_holdout)\n",
    "\n",
    "params_grid={\n",
    "    # 'vect__min_df' : [2], #np.arange(2,6)\n",
    "    # 'vect__ngram_range': [(1,2)], #(1,2) 0.871\n",
    "\n",
    "    # 'clf__alpha': [1], #[0.1, 1, 10, 100]\n",
    "    # 'knn__n_neighbors': [8], #range(5,10) \n",
    "    # 'dtree__random_state':[0]\n",
    "    # 'line_svc__C': [ 0.025] #too slow\n",
    "\n",
    "    # 'tsvd__n_components': [200], #for svc models\n",
    "    # 'svc__gamma': [2],\n",
    "    # 'svc__C' :[1]\n",
    "\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "grid=GridSearchCV(pipeline, param_grid=params_grid, scoring='accuracy', cv=5, n_jobs=5, verbose=3)\n",
    "grid.fit(x,y)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "\n",
    "e.append(str(grid.best_estimator_).split(\"\\n\")[3])\n",
    "s.append(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8736"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(x_holdout, y_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "if 'nltk' not in sys.modules:\n",
    "    import nltk\n",
    "    nltk.download('vader_lexicon')\n",
    "\n",
    "    from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    \n",
    "def vader(x):\n",
    "    vader_out = x.apply(lambda review: sid.polarity_scores(review))\n",
    "    scores=vader_out.apply(pd.Series)\n",
    "\n",
    "    # x_out=hstack((x, scores))\n",
    "    return scores\n",
    "\n",
    "\n",
    "\n",
    "class add_vader:\n",
    "    def __init__(self) -> None:\n",
    "        # print(\"Initialer called\")\n",
    "        return self\n",
    "\n",
    "    def fit(self, input):\n",
    "        print(\"Fit called\")\n",
    "        return self  #important to have a return self statement apparently for the later transform operation in the pipeline\n",
    "\n",
    "    def transform(self, input):\n",
    "        if input.shape[0] == x.shape[0]:\n",
    "            vader_scores=vader(x)\n",
    "\n",
    "        elif input.shape[0] == x_holdout.shape[0]:\n",
    "            vader_scores=vader(x_holdout)        \n",
    "\n",
    "        else:\n",
    "            return input\n",
    "\n",
    "        x_out=hstack((input, vader_scores))\n",
    "        return x_out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#vader(x_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd=vader(x)\n",
    "\n",
    "vd.compound=(vd.compound+1)/2\n",
    "\n",
    "#0.7 accuracy score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Comparing the Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim= { \"                ('clf', MultinomialNB(alpha=1))])\": 0.876,\n",
    "\"                ('knn', KNeighborsClassifier(n_neighbors=8))])\": 0.7891111111111111,\n",
    " \"                ('dtree', DecisionTreeClassifier(random_state=0))])\": 0.7053777777777778,\n",
    " \"                ('tsvd', TruncatedSVD(n_components=200)),\": 0.8637777777777776,\n",
    " \"                ('randomf', RandomForestClassifier())])\": 0.8478666666666667\n",
    " }"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
